---
title: "Mini Project Team 2"
authors: "By: Cooper, Nusrat, Ricardo, and Varun"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
library(dplyr)
library(lmtest)
library(vcd)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# use scipen=999 to prevent scientific notation at all times
```

Let's first import our dataset before we do any analysis. Our dataset is based on possible variables that could be used to predict loan default status for employed individuals in India.

```{r loanpredict}
#Import dataset
loanpredict <- read.csv("Training Data.csv", header = TRUE)
str(loanpredict)
#Convert necessary variables to factors/categoricals and set appropriate level titles
loanpredict$Married.Single <- recode_factor(loanpredict$Married.Single, single = "Single", married = "Married")

loanpredict$House_Ownership <- recode_factor(loanpredict$House_Ownership, rented = "Renting", owned = "Owning", norent_noown = "Neither")

loanpredict$Car_Ownership <- recode_factor(loanpredict$Car_Ownership, no = "No", yes = "Yes")

#Remove variables that won't help in our analysis
loandata <- subset(loanpredict, select = -c(Id, CITY, STATE, Profession))

#Create summary table of remaining variables
xkablesummary(loandata, title = "Summary Statistics for Loan Default Prediction")
#Selecting only values where the customer defaulted
defaulted <- subset(loandata, Risk_Flag == 1)

#Selecting only values where the customer did not default
not_defaulted <- subset(loandata, Risk_Flag == 0)
```

In our previous report, we conducted some exploratory data analysis (EDA) and determined that there were significant differences between those who defaulted on their loans and those who didn't in terms of home-ownership status, marital status, years of home-ownership, job experience, years of experience in current job, and age. Notably, we did not see a significant difference in income levels between the two populations.

Having completed this EDA, we now want to develop a model to predict the likelihood of default status based on these variables provided at the time of the loan application. If we were a bank, this would allow us to predict who we should and shouldn't approve for loans.

Once again, we've developed some questions to help guide us in the model development process:
	• Despite not being useful on it's own, is income statistically significant in a model when other variables are included?
	• Does current job experience or overall job experience yield a better model?
	• For each additional year, how does age impact likelihood of defaulting on a loan?
	• For each additional year, how does job experience (whichever version was deemed more significant before) impact likelihood of defaulting on a loan?
	• Does manual, exhaustive stepwise, or other modelling techniques produce a better model using the different methods (AIC, BIC, pseudo-R^2 etc.)
	• Does each method for model selection produce a significant model as determined by ROC-AUC >= 0.8, and if so, which produces the best? Does it agree with what we said before?
	• What are the most significant predictors for default, and do they appear across all of the "best" models?
	• Using a confusion matrix, which of our "best" models appears to perform best across the different metrics we care about (precision, recall-rate, etc.)
	• How do the different models fare when used on the test dataset? 	
	
To begin with, let's go ahead and use the knowledge we learned through EDA to develop some logistic regression models manually. This will allow us to then guage how good our "best" models are against what we think should be a good model.

# Preliminary Model Development

As mentioned earlier, we know that the following variables are significant between default and non-default status on loans:
	• Home-Ownership Status  
	• Years of Home-Ownership  
	• Marital Status  
	• Years Overall Job Experience  
	• Years Current Job Experience  
	• Age  

We'll go ahead and start developing our logistic regression model based on background knowledge. We'll first try running our model with only years of overall job experience as a predictor. Note: all variable significance will be run against $\alpha$ = 0.05

```{r}
only_exp <- glm(Risk_Flag ~ CURRENT_JOB_YRS, data = loandata, family = 'binomial')
summary(only_exp)
```

We can see here that our current_job_yrs, as expected, is highly significant with a p-value of <0.001. However, we already know that years in current job is highly correlated with overall years of job experience. Before proceeding with our current model, we should run this model using overall years of job experience to determine which is a better predictor in a single variable model.

```{r}
overall_exp <- glm(Risk_Flag ~ Experience, data = loandata, family = 'binomial')
summary(overall_exp)
```

When we build our model with overall years of job experience, we once again get a highly significant p-value of <0.001. Notably, our standard error is 0.00101 here, while for current job experience, it was 0.00167. That means, that although both variables are highly significant, overall years of job experience is slightly more, so we'll proceed using that variable in our model.

Now, let's try adding in a second variable. Let's try home_ownership status to determine if that has an effect when combined with overall years of job experience.

```{r}
house_job_exp <- glm(Risk_Flag ~ Experience + House_Ownership, data = loandata, family = 'binomial')
summary(house_job_exp)
```

Once again, all of our variables are significant in our model, which is to be expected. Let's also consider adding in an interaction variable.

```{r}
house_job_exp_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Experience:House_Ownership, data = loandata, family = 'binomial')
summary(house_job_exp_inter)
```

Here, we see that our interaction terms are exceptionally insignificant, so we will remove those as we continue developing our model. Now, let's try adding in a third variable. Let's try adding in years in current house. If it is determined to be significant, we will check VIF afterwards to ensure we aren't having multicollinearity issues with the two housing variables.

```{r}
house_job_exp_house <- glm(Risk_Flag ~ Experience + House_Ownership + CURRENT_HOUSE_YRS, data = loandata, family = 'binomial')
summary(house_job_exp_house)
```

Years in current housing is insignificant in our model when we already know overall job experience and house ownership status. This means that owning a house is more important than how long you've owned it for. Let's try removing this variable and instead adding in age, our last variable we know for sure is significantly different between those who do and don't default on their loans. Again, if it's significant we'll go ahead and run a VIF analysis to confirm there's no multicollinearity with overall years of job experience.

```{r}
house_job_exp_age <- glm(Risk_Flag ~ Experience + House_Ownership + Age, data = loandata, family = 'binomial')
summary(house_job_exp_age)
library(car)
vif(house_job_exp_age)
```

Fortunately for us, age is a significant variable with a p-value <0.001. Checking the VIF values, we see that they're all low, so we can include age in our model without multicollinearity concerns. As before, let's try adding in an interaction term to see how it behaves. We'll also retry the interaction term between job experience and house ownership to see if that term is significant when age is accounted for.

```{r}
house_job_exp_age_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Experience:House_Ownership + Experience:Age + House_Ownership:Age, data = loandata, family = 'binomial')
summary(house_job_exp_age_inter)
```

Looking at our model outputs, we see that all of our non-interaction variables are still significant. Additionally, we see that the interaction between job experience and age is significant, as well as the interaction between home ownership (Neither) and age is significant. Notably, the interaction between job experience and home ownership is still not significant and the interaction between home ownership (Owning) and age is not significant. However, since one of the two home ownership categorical variables is significant with age, we'll keep both in the model.

```{r}
house_job_exp_age_limit_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age +  Experience:Age + House_Ownership:Age, data = loandata, family = 'binomial')
summary(house_job_exp_age_limit_inter)
```

As expected, when we rerun the model without the insignificant job experience and house ownership interaction term, we get that our remaining variables are significant enough to keep in the model, or are necessary to keep in combination with a significant term in the model.  

Now, let's try adding in marital status, our final variable we know has significance on it's own.
```{r}
house_job_exp_age_limit_marital <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + Experience:Age + House_Ownership:Age, data = loandata, family = 'binomial')
summary(house_job_exp_age_limit_marital)
```

We see here that marital status is significant in our model with a p-value <0.001.

```{r}
house_job_exp_age_limit_marital_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + Experience:Age + House_Ownership:Age + Experience:Married.Single + House_Ownership:Married.Single + Age:Married.Single, data = loandata, family = 'binomial')
summary(house_job_exp_age_limit_marital_inter)
```
Examining a model with the interaction terms, the interaction of home ownership and marriage status is significant for the combination of owning a home and married relative to the base value of Renting and Single.

Now, let's see what happens if we add income into our model. From our EDA we found that income was not significantly different between those who defaulted on their loans and those who didn't. However, we're curious to see if income is a significant variable when we are already considering job experience, home ownership status, age, and the combinations of home ownership and age plus job experience and age.

```{r}
house_job_exp_age_limit_marital_income <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + Income + Experience:Age + House_Ownership:Age + House_Ownership:Married.Single, data = loandata, family = 'binomial')
summary(house_job_exp_age_limit_marital_income)
```

Based on our model outputs, income doesn't provide added value when we already know the information from our previous model. Based on our EDA, this is expected, but based on how important income is as a risk splitter in the United States, this is quite surprising that income remains so insignificant as a predictor.

Finally, let's see what happens if we add in car ownership to our model.
```{r}
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + Income + Car_Ownership + Experience:Age + House_Ownership:Age + House_Ownership:Married.Single, data = loandata, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
```

When we add in car ownership, we see that income becomes insignificant, while everything else remains significant. This means that knowing an individuals income or car ownership status is significant, but not both when we already know this other information. If we examine our AIC values, we see that when our model uses income, we have an AIC of `r house_job_exp_age_limit_marital_income$aic`, while our model that uses car ownership has an AIC of `r house_job_exp_age_limit_marital_income_car$aic`. Therefore, if we use AIC as our criteria of "goodness", then our model using car ownership is the better model.

ADDITIONAL ANALYSIS OF THIS MODEL INCLUDING ROC-AUC, PSEUDO-R^2, CONFUSION MATRIX, ETC.


Now that we've developed a model manually that's significant, let's see what happens if we use algorithms to build a good model.






# Backwards Selection


Backward selection on AIC:


```{r}
# Specify a null model with no predictors
null_model <- glm(Risk_Flag ~ 1, data = loandata, family = "binomial")

# Specify the full model using all of the potential predictors
full_model <- glm(Risk_Flag ~ ., data = loandata, family = "binomial")

# Use a backward stepwise algorithm on AIC to build a parsimonious model
bkwrd_AIC_model_vars <- step(full_model, scope = list(lower = null_model, upper = full_model), direction = "backward", k=2)
```



If we consider AIC as a criterion we should have all the 8 variables in the logistics model.

Now let's the the VIF score to find out the multicolinearity.
```{r}
# library(car)
# xkablevif(full_model, wide=FALSE)
vif(full_model)
```

Confusion matrix:

```{r}
loadPkg("regclass")
cmaic <- confusion_matrix(full_model)
xkabledply( cmaic, title = "Confusion matrix from Logit Model on AIC" )
accuracy1 = (cmaic[1] +cmaic[5]) / cmaic[9]
unloadPkg("regclass")
```

<!-- Accuracy of the backward AIC model is `r round(accuracy1 * 100) ` % -->


Backward selection on BIC:

```{r}
# Use a backward stepwise algorithm on BIC to build a parsimonious model
bkwrd_BIC_model_vars <- step(full_model, scope = list(lower = null_model, upper = full_model), direction = "backward", k=log(nrow(loandata)))
```

From backward selection with BIC as criteria we are getting 6 features. It excluded Income and CURRENT_HOUSE_YRS. Now let's make a model with these 6 features.


```{r}

bkwd_bic_model <- glm(Risk_Flag ~ CURRENT_JOB_YRS+Age+Married.Single+Car_Ownership+House_Ownership+Experience, data = loandata, family = "binomial")
summary(bkwd_bic_model)

```

Now let's the the VIF score to find out the multicolinearity.
```{r}
# library(car)
# xkablevif(bkwd_bic_model, wide=FALSE)
vif(bkwd_bic_model) 
```

All the VIF scores are satisfactory. It means we don't have multicolinearity in this model.

Confusion Matrix:

```{r}
loadPkg("regclass")
cmbic <- confusion_matrix(bkwd_bic_model)
xkabledply( cmbic, title = "Confusion matrix from Logit Model on BIC" )
unloadPkg("regclass")
accuracy2 = (cmbic[1] +cmbic[5]) / cmbic[9]
```

<!-- Accuracy of the backward BIC model is `r round(accuracy2 * 100) ` % -->



# Forward Selection



```{r}

foward_aic_model <- step(full_model, direction = "forward", k=2) # k=2 refers to AIC 

```

According to the AIC Foward selection method we should have all the 8 variables in the logistics model.


Forward selection on BIC:

```{r}
fwd_BIC_model <- step(full_model, direction = "forward", k=log(nrow(loandata))) #k = log(n) is sometimes referred to as BIC or SBC.
```

From forward selection with BIC as criteria we are getting 8 features also. 

# ROC- AUC

```{r}
loadPkg('pROC')
prob = predict(full_model,type = 'response') ## foward selection results = full_model 
loandata$prob = prob
h <- roc(Risk_Flag ~ prob, data = loandata)
auc(h)
plot(h)

```

#Confusion matrix:


```{r}
library(caret)
confusionMatrix(as.factor(ifelse(loandata$prob >0.15,0,1)), as.factor(loandata$Risk_Flag))

```



# Exhaustive Selection






# Splitting the dataset

```{r}
library(caTools)

loandata$Risk_Flag <- as.factor(loandata$Risk_Flag)


split <- sample.split(loandata, SplitRatio = 0.75)
split
   
train_reg <- subset(loandata, split == "TRUE")
test_reg <- subset(loandata, split == "FALSE")

```


# Random Forest 


Model

```{r}
#install.packages("randomForest")
library(randomForest)


rf <- randomForest(Risk_Flag ~ ., data = train_reg, ntree = 100)
# predicting in test set
predict_test <- predict(rf, test_reg, type = 'response')
#confusion matrix  
cm <- table(test_reg$Risk_Flag, predict_test)
xkabledply( cm, title = "Confusion matrix from Random Forest" )
# Accuracy
missing_classerr <- mean(predict_test != test_reg$Risk_Flag)
print(paste('Random Forest Accuracy =', 1 - missing_classerr))

#plot(rf)



```






#"Best" Model Comparisons

Now that we've developed models manually and with various selection methods, we'll compare all of our final models to determine which model is the best model. We'll start with an analysis of our model diagnostics between each model before running each model against our test dataset to confirm we aren't seeing over fitting.

The final model for manual logistic regression was: 
(This will be deleted, but just for model name reference for comparison coding)
```{r}
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + Income + Car_Ownership + Experience:Age + House_Ownership:Age + House_Ownership:Married.Single, data = loandata, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
```

The final model for backwards selection was: **"Risk_Flag ~ CURRENT_JOB_YRS+Age+Married.Single+Car_Ownership+House_Ownership+Experience"**

The final model for forward selection was: **"Risk_Flag ~ Income + Age + Experience + Married.Single + House_Ownership + 
    Car_Ownership + CURRENT_JOB_YRS + CURRENT_HOUSE_YRS"**

The final model for exhaustive selection was: 



### Comparison of AIC

### Comparison of BIC

### Comparison of Pseudo-R-Squared

### Comparison of ROC-AUC

## Using our Test Dataset
### Comparison of Confusion Matrix (is this a confusion matrix or is this called something else)





# Conclusion and answers to questions plus overview of our final model in terms of expected likelihood changes for differences in our variables