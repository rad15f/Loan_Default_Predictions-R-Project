dt <- rpart(Risk_Flag ~ ., data = train_reg, method= "class")
# predicting in test set
predict_dt_test <- predict(dt, test_reg, type = 'class')
#confusion matrix
cmdt <- table(test_reg$Risk_Flag, predict_dt_test)
xkabledply( cmdt, title = "Confusion matrix from Decision Tree" )
# Accuracy
acc_dt <-  sum(diag(cmdt)) / sum(cmdt)
print(paste('Decision Tree Accuracy =', acc_dt))
# plot(dt)
accuracy_tune <- function(fit) {
predict_unseen <- predict(fit, test_reg, type = 'class')
table_mat <- table(test_reg$Risk_Flag, predict_unseen)
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
}
control <- rpart.control(minsplit = 3,
minbucket = round(4 / 3),
maxdepth = 30,
cp = 0)
tune_fit <- rpart(Risk_Flag~., data = train_reg, method = 'class', control = control)
accuracy_tune(tune_fit)
#confusion matrix
predict_dt_test_tune <- predict(tune_fit, test_reg, type = 'class')
cmdtt <- table(test_reg$Risk_Flag, predict_dt_test_tune)
xkabledply( cmdtt, title = "Confusion matrix from Tuned Decision Tree" )
plot(tune_fit)
# text(tune_fit, use.n=TRUE, all=TRUE, cex=.8)
#ROC-AUC Calculation for Decision Tree
pred <- predict(tune_fit, newdata=test_reg)
test_reg$prob_dt <- ifelse(pred[,1] > 0.855,0,1)
dt_h <- roc(Risk_Flag ~ prob_aic, data = test_reg)
auc(dt_h)
plot(dt_h)
# library(caret)
# varImp(tune_fit)
#install.packages("randomForest")
rf <- randomForest(Risk_Flag ~ ., data = train_reg, ntree = 100)
# predicting in test set
predict_test <- predict(rf, test_reg, type = 'response')
#confusion matrix
rf_cm <- table(test_reg$Risk_Flag, predict_test)
xkabledply( rf_cm, title = "Confusion matrix from Random Forest" )
# Accuracy
missing_classerr <- mean(predict_test != test_reg$Risk_Flag)
print(paste('Random Forest Accuracy =', 1 - missing_classerr))
plot(rf)
test_reg$prob_rf <- ifelse(predict_test == 1,1,0)
rf_h <- roc(Risk_Flag ~ prob_rf, data = test_reg)
auc(rf_h)
plot(rf_h)
expcoeff_exh_aic = exp(coef(riskaic))
# expcoeff
xkabledply( as.table(expcoeff_exh_aic), title = "Exponential of coefficients in Exhaustive AIC Logit Reg" )
#Sensitivity (Recall Rate)
manual_cm$byClass[1]
bkwd_cm$byClass[1]
fwd_cm$byClass[1]
exh_aic_cm$byClass[1]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2])
#Specficity
manual_cm$byClass[2]
bkwd_cm$byClass[2]
fwd_cm$byClass[2]
exh_aic_cm$byClass[2]
cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2])
rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2])
#Precision
manual_cm$byClass[5]
bkwd_cm$byClass[5]
fwd_cm$byClass[5]
exh_aic_cm$byClass[5]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2])
#Accuracy
manual_accuracy
bkwd_accuracy
fwd_accuracy
exh_aic_accuracy
accuracy_tune(tune_fit)
1-missing_classerr
manual_cm$byClass[1]
bkwd_cm$byClass[1]
fwd_cm$byClass[1]
exh_aic_cm$byClass[1]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2])
#confusion matrix
rf_cm <- table(test_reg$Risk_Flag, predict_test)
rf_cm
manual_cm$byClass[2]
bkwd_cm$byClass[2]
fwd_cm$byClass[2]
exh_aic_cm$byClass[2]
cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2])
rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2])
manual_cm$byClass[5]
bkwd_cm$byClass[5]
fwd_cm$byClass[5]
exh_aic_cm$byClass[5]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2])
manual_accuracy
bkwd_accuracy
fwd_accuracy
exh_aic_accuracy
accuracy_tune(tune_fit)
1-missing_classerr
manual_cm$byClass[5]
bkwd_cm$byClass[5]
fwd_cm$byClass[5]
exh_aic_cm$byClass[5]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2])
manual_cm$byClass[2]
bkwd_cm$byClass[2]
fwd_cm$byClass[2]
exh_aic_cm$byClass[2]
cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2])
rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2])
manual_cm$byClass[1]
bkwd_cm$byClass[1]
fwd_cm$byClass[1]
exh_aic_cm$byClass[1]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2])
manual_cm$byClass[1]
bkwd_cm$byClass[1]
fwd_cm$byClass[1]
exh_aic_cm$byClass[1]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2])
manual_cm$byClass[2]
bkwd_cm$byClass[2]
fwd_cm$byClass[2]
exh_aic_cm$byClass[2]
cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2])
rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2])
manual_cm$byClass[5]
bkwd_cm$byClass[5]
fwd_cm$byClass[5]
exh_aic_cm$byClass[5]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2])
manual_accuracy
bkwd_accuracy
fwd_accuracy
exh_aic_accuracy
accuracy_tune(tune_fit)
1-missing_classerr
auc(rf_h)
(1-expcoeff_exh_aic[2])*100
# expcoeff
xkabledply( as.table(expcoeff_exh_aic), title = "Exponential of coefficients in Exhaustive AIC Logit Reg" )
expcoeff_exh_aic[2]
1-expcoeff_exh_aic[2]
(1-expcoeff_exh_aic[2])*100
(1-expcoeff_exh_aic[3])*100
house_job_exp_age_limit_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age + House_Ownership:Age, data = train_reg, family = 'binomial')
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single  + Car_Ownership  + House_Ownership:Age + House_Ownership:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
knitr::opts_chunk$set(echo = TRUE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
library(dplyr)
library(lmtest)
library(vcd)
library(bestglm)
library(caTools)
library(car)
library(pROC)
library(caret)
library(regclass)
library(ResourceSelection)
library(rpart)
library(rpart.plot)
library(randomForest)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# use scipen=999 to prevent scientific notation at all times
#Import dataset
loanpredict <- read.csv("Training Data.csv", header = TRUE)
str(loanpredict)
#Convert necessary variables to factors/categoricals and set appropriate level titles
loanpredict$Married.Single <- recode_factor(loanpredict$Married.Single, single = "Single", married = "Married")
loanpredict$House_Ownership <- recode_factor(loanpredict$House_Ownership, rented = "Renting", owned = "Owning", norent_noown = "Neither")
loanpredict$Car_Ownership <- recode_factor(loanpredict$Car_Ownership, no = "No", yes = "Yes")
#Remove variables that won't help in our analysis
loandata <- subset(loanpredict, select = -c(Id, CITY, STATE, Profession))
#Create summary table of remaining variables
xkablesummary(loandata, title = "Summary Statistics for Loan Default Prediction")
#Selecting only values where the customer defaulted
defaulted <- subset(loandata, Risk_Flag == 1)
#Selecting only values where the customer did not default
not_defaulted <- subset(loandata, Risk_Flag == 0)
loandata$Risk_Flag <- as.factor(loandata$Risk_Flag)
set.seed(123)
split <- sample.split(loandata, SplitRatio = 0.75)
# split
train_reg <- subset(loandata, split == "TRUE")
test_reg <- subset(loandata, split == "FALSE")
only_exp <- glm(Risk_Flag ~ CURRENT_JOB_YRS, data = train_reg, family = 'binomial')
summary(only_exp)
overall_exp <- glm(Risk_Flag ~ Experience, data = train_reg, family = 'binomial')
summary(overall_exp)
house_job_exp <- glm(Risk_Flag ~ Experience + House_Ownership, data = train_reg, family = 'binomial')
summary(house_job_exp)
house_job_exp_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Experience:House_Ownership, data = train_reg, family = 'binomial')
summary(house_job_exp_inter)
house_job_exp_house <- glm(Risk_Flag ~ Experience + House_Ownership + CURRENT_HOUSE_YRS, data = train_reg, family = 'binomial')
summary(house_job_exp_house)
house_job_exp_age <- glm(Risk_Flag ~ Experience + House_Ownership + Age, data = train_reg, family = 'binomial')
summary(house_job_exp_age)
vif(house_job_exp_age)
house_job_exp_age_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Experience:House_Ownership + Experience:Age + House_Ownership:Age, data = train_reg, family = 'binomial')
summary(house_job_exp_age_inter)
house_job_exp_age_limit_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age + House_Ownership:Age, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_inter)
house_job_exp_age_limit_marital <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + House_Ownership:Age, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital)
house_job_exp_age_limit_marital_inter <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + House_Ownership:Age + Experience:Married.Single + House_Ownership:Married.Single + Age:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_inter)
house_job_exp_age_limit_marital_income <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single + Income + House_Ownership:Age + House_Ownership:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_income)
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single  + Car_Ownership  + House_Ownership:Age + House_Ownership:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
prob_predict_manual <- predict(house_job_exp_age_limit_marital_income_car, test_reg, type='response')
test_reg$prob_manual <- ifelse(prob_predict_manual > 0.145,1,0)
h_manual <- roc(Risk_Flag ~ prob_manual, data = test_reg)
auc(h_manual)
plot(h_manual)
manual_cm <- confusionMatrix(as.factor(test_reg$prob_manual), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted", "Actual"), positive = '1')
xkabledply(manual_cm$table)
manual_accuracy <- (manual_cm$table[4:4]+manual_cm$table[1:1])/(manual_cm$table[4:4]+manual_cm$table[1:1]+manual_cm$table[2:2]+manual_cm$table[3:3])
expcoeff = exp(coef(house_job_exp_age_limit_marital_income_car))
# expcoeff
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Manual Logit Reg" )
manual_cm$byClass[1]
bkwd_cm$byClass[1]
fwd_cm$byClass[1]
exh_aic_cm$byClass[1]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2])
manual_cm$byClass[2]
bkwd_cm$byClass[2]
fwd_cm$byClass[2]
exh_aic_cm$byClass[2]
cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2])
rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2])
manual_cm$byClass[5]
bkwd_cm$byClass[5]
fwd_cm$byClass[5]
exh_aic_cm$byClass[5]
cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2])
rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2])
manual_accuracy
bkwd_accuracy
fwd_accuracy
exh_aic_accuracy
accuracy_tune(tune_fit)
1-missing_classerr
auc(h_manual)
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Income + Age + Married.Single  + Car_Ownership  + House_Ownership:Age + House_Ownership:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single  + Car_Ownership  + House_Ownership:Age + House_Ownership:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
# expcoeff
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Manual Logit Reg" )
install.packages('tabyl')
knitr::opts_chunk$set(echo = TRUE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
library(dplyr)
library(lmtest)
library(vcd)
library(bestglm)
library(caTools)
library(car)
library(pROC)
library(caret)
library(regclass)
library(ResourceSelection)
library(rpart)
library(rpart.plot)
library(randomForest)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# use scipen=999 to prevent scientific notation at all times
#Import dataset
loanpredict <- read.csv("Training Data.csv", header = TRUE)
str(loanpredict)
#Convert necessary variables to factors/categoricals and set appropriate level titles
loanpredict$Married.Single <- recode_factor(loanpredict$Married.Single, single = "Single", married = "Married")
loanpredict$House_Ownership <- recode_factor(loanpredict$House_Ownership, rented = "Renting", owned = "Owning", norent_noown = "Neither")
loanpredict$Car_Ownership <- recode_factor(loanpredict$Car_Ownership, no = "No", yes = "Yes")
#Remove variables that won't help in our analysis
loandata <- subset(loanpredict, select = -c(Id, CITY, STATE, Profession))
#Create summary table of remaining variables
xkablesummary(loandata, title = "Summary Statistics for Loan Default Prediction")
#Selecting only values where the customer defaulted
defaulted <- subset(loandata, Risk_Flag == 1)
#Selecting only values where the customer did not default
not_defaulted <- subset(loandata, Risk_Flag == 0)
#Split data into Test and Train (75%-25%)
loandata$Risk_Flag <- as.factor(loandata$Risk_Flag)
set.seed(123)
split <- sample.split(loandata, SplitRatio = 0.75)
# split
train_reg <- subset(loandata, split == "TRUE")
test_reg <- subset(loandata, split == "FALSE")
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
knitr::opts_chunk$set(echo = TRUE)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
library(dplyr)
library(lmtest)
library(vcd)
library(bestglm)
library(caTools)
library(car)
library(pROC)
library(caret)
library(regclass)
library(ResourceSelection)
library(rpart)
library(rpart.plot)
library(randomForest)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# use scipen=999 to prevent scientific notation at all times
#Import dataset
loanpredict <- read.csv("Training Data.csv", header = TRUE)
str(loanpredict)
#Convert necessary variables to factors/categoricals and set appropriate level titles
loanpredict$Married.Single <- recode_factor(loanpredict$Married.Single, single = "Single", married = "Married")
loanpredict$House_Ownership <- recode_factor(loanpredict$House_Ownership, rented = "Renting", owned = "Owning", norent_noown = "Neither")
loanpredict$Car_Ownership <- recode_factor(loanpredict$Car_Ownership, no = "No", yes = "Yes")
#Remove variables that won't help in our analysis
loandata <- subset(loanpredict, select = -c(Id, CITY, STATE, Profession))
#Create summary table of remaining variables
xkablesummary(loandata, title = "Summary Statistics for Loan Default Prediction")
#Selecting only values where the customer defaulted
defaulted <- subset(loandata, Risk_Flag == 1)
#Selecting only values where the customer did not default
not_defaulted <- subset(loandata, Risk_Flag == 0)
#Split data into Test and Train (75%-25%)
loandata$Risk_Flag <- as.factor(loandata$Risk_Flag)
set.seed(123)
split <- sample.split(loandata, SplitRatio = 0.75)
# split
train_reg <- subset(loandata, split == "TRUE")
test_reg <- subset(loandata, split == "FALSE")
house_job_exp_age_limit_marital_income_car <- glm(Risk_Flag ~ Experience + House_Ownership + Age + Married.Single  + Car_Ownership  + House_Ownership:Age + House_Ownership:Married.Single, data = train_reg, family = 'binomial')
summary(house_job_exp_age_limit_marital_income_car)
prob_predict_manual <- predict(house_job_exp_age_limit_marital_income_car, test_reg, type='response')
test_reg$prob_manual <- ifelse(prob_predict_manual > 0.145,1,0)
h_manual <- roc(Risk_Flag ~ prob_manual, data = test_reg)
auc(h_manual)
plot(h_manual)
manual_cm <- confusionMatrix(as.factor(test_reg$prob_manual), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted", "Actual"), positive = '1')
manual_cm
xkabledply(manual_cm$table)
manual_accuracy <- (manual_cm$table[4:4]+manual_cm$table[1:1])/(manual_cm$table[4:4]+manual_cm$table[1:1]+manual_cm$table[2:2]+manual_cm$table[3:3])
bkwd_bic_model <- glm(Risk_Flag ~ Age+Married.Single+Car_Ownership+House_Ownership+Experience, data = train_reg, family = "binomial")
summary(bkwd_bic_model)
prob_predictbic <- predict(bkwd_bic_model, test_reg, type='response')
test_reg$prob_bic <- ifelse(prob_predictbic > 0.145,1,0)
bkwd_h <- roc(Risk_Flag ~ prob_bic, data = test_reg)
auc(bkwd_h)
bkwd_cm <- confusionMatrix(as.factor(test_reg$prob_bic), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted", "Actual"), positive = '1')
xkabledply(bkwd_cm$table)
bkwd_cm
fwd_BIC_model <- glm(Risk_Flag ~ Experience + House_Ownership + Car_Ownership + Married.Single + Age, data = train_reg, family = "binomial")
summary(fwd_BIC_model)
prob_predictaic <- predict(fwd_BIC_model, test_reg, type='response')
test_reg$prob_aic <- ifelse(prob_predictaic > 0.115,1,0)
fwd_h <- roc(Risk_Flag ~ prob_aic, data = test_reg)
auc(fwd_h)
fwd_cm <- confusionMatrix(as.factor(test_reg$prob_aic), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted", "Actual"), positive = '1')
xkabledply(fwd_cm$table)
fwd_cm
riskbic <- glm(Risk_Flag ~ Age +
Experience +
Married.Single +
House_Ownership +
Car_Ownership, data = train_reg, family = "binomial")
summary(riskbic)
test_reg$predictedRisk_bic <- ifelse(prob_predict_bic > 0.15, 1, 0)
prob_predict_bic <- predict(riskbic, test_reg, type = 'response')
test_reg$predictedRisk_bic <- ifelse(prob_predict_bic > 0.15, 1, 0)
exh_bic_cm <- confusionMatrix(as.factor(test_reg$predictedRisk_bic), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted","Actual"), positive = '1')
exh_bic_cm
exh_bic_accuracy <- (exh_bic_cm$table[4:4]+exh_bic_cm$table[1:1])/(exh_bic_cm$table[4:4]+exh_bic_cm$table[1:1]+exh_bic_cm$table[2:2]+exh_bic_cm$table[3:3])
exh_bic_accuracy
h_exh_bic <- roc(Risk_Flag ~ prob_predict_bic, data=test_reg)
auc(h_exh_bic) # area-under-curve prefer 0.8 or higher.
plot(h_exh_bic)
accuracy_tune <- function(fit) {
predict_unseen <- predict(fit, test_reg, type = 'class')
table_mat <- table(test_reg$Risk_Flag, predict_unseen)
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
}
control <- rpart.control(minsplit = 4,
minbucket = round(4 / 3),
maxdepth = 30,
cp = 0)
tune_fit <- rpart(Risk_Flag~., data = train_reg, method = 'class', control = control)
accuracy_tune(tune_fit)
pred <- predict(tune_fit, newdata=test_reg)
test_reg$prob_dt <- ifelse(pred[,1] > 0.855,0,1)
dt_h <- roc(Risk_Flag ~ prob_aic, data = test_reg)
auc(dt_h)
predict_dt_test_tune <- predict(tune_fit, test_reg, type = 'class')
cmdtt <- table(test_reg$Risk_Flag, predict_dt_test_tune)
xkabledply( cmdtt, title = "Confusion matrix from Tuned Decision Tree" )
pred <- predict(tune_fit, newdata=test_reg)
test_reg$prob_dt <- ifelse(pred[,1] > 0.855,0,1)
dt_h <- roc(Risk_Flag ~ prob_aic, data = test_reg)
auc(dt_h)
plot(dt_h)
rf <- randomForest(Risk_Flag ~ ., data = train_reg, ntree = 100)
# predicting in test set
predict_test <- predict(rf, test_reg, type = 'response')
#confusion matrix
rf_cm <- table(test_reg$Risk_Flag, predict_test)
xkabledply( rf_cm, title = "Confusion matrix from Random Forest" )
missing_classerr <- mean(predict_test != test_reg$Risk_Flag)
print(paste('Random Forest Accuracy =', 1 - missing_classerr))
test_reg$prob_rf <- ifelse(predict_test == 1,1,0)
rf_h <- roc(Risk_Flag ~ prob_rf, data = test_reg)
auc(rf_h)
plot(rf_h)
#confusion matrix
confusionMatrix(predict_test,test_reg$Risk_Flag)
rf <- randomForest(Risk_Flag ~ ., data = train_reg, ntree = 100)
# predicting in test set
predict_test <- predict(rf, test_reg, type = 'response')
#confusion matrix
confusionMatrix(predict_test,test_reg$Risk_Flag)
rf_cm <- table(test_reg$Risk_Flag, predict_test)
xkabledply( rf_cm, title = "Confusion matrix from Random Forest" )
predict_dt_test_tune <- predict(tune_fit, test_reg, type = 'class')
cmdtt <- table(test_reg$Risk_Flag, predict_dt_test_tune)
xkabledply( cmdtt, title = "Confusion matrix from Tuned Decision Tree" )
confusionMatrix(predict_dt_test_tune,test_reg$Risk_Flag)
accuracy_tune <- function(fit) {
predict_unseen <- predict(fit, test_reg, type = 'class')
table_mat <- table(test_reg$Risk_Flag, predict_unseen)
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
}
control <- rpart.control(minsplit = 4,
minbucket = 2,
maxdepth = 30,
cp = 0)
tune_fit <- rpart(Risk_Flag~., data = train_reg, method = 'class', control = control)
accuracy_tune(tune_fit)
predict_dt_test_tune <- predict(tune_fit, test_reg, type = 'class')
cmdtt <- table(test_reg$Risk_Flag, predict_dt_test_tune)
xkabledply( cmdtt, title = "Confusion matrix from Tuned Decision Tree" )
confusionMatrix(predict_dt_test_tune,test_reg$Risk_Flag)
accuracy_tune <- function(fit) {
predict_unseen <- predict(fit, test_reg, type = 'class')
table_mat <- table(test_reg$Risk_Flag, predict_unseen)
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
}
control <- rpart.control(minsplit = 4,
minbucket = round(4 / 3),
maxdepth = 30,
cp = 0)
tune_fit <- rpart(Risk_Flag~., data = train_reg, method = 'class', control = control)
accuracy_tune(tune_fit)
predict_dt_test_tune <- predict(tune_fit, test_reg, type = 'class')
cmdtt <- table(test_reg$Risk_Flag, predict_dt_test_tune)
xkabledply( cmdtt, title = "Confusion matrix from Tuned Decision Tree" )
confusionMatrix(predict_dt_test_tune,test_reg$Risk_Flag)
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
bkwd_cm <- confusionMatrix(as.factor(test_reg$prob_bic), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted", "Actual"), positive = '1')
xkabledply(bkwd_cm$table)
bkwd_accuracy <- (bkwd_cm$table[4:4]+bkwd_cm$table[1:1])/(bkwd_cm$table[4:4]+bkwd_cm$table[1:1]+bkwd_cm$table[2:2]+bkwd_cm$table[3:3])
bkwd_cm
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
fwd_cm <- confusionMatrix(as.factor(test_reg$prob_aic), as.factor(test_reg$Risk_Flag), mode = "everything", dnn = c("Predicted", "Actual"), positive = '1')
xkabledply(fwd_cm$table)
fwd_accuracy <- (fwd_cm$table[4:4]+fwd_cm$table[1:1])/(fwd_cm$table[4:4]+fwd_cm$table[1:1]+fwd_cm$table[2:2]+fwd_cm$table[3:3])
fwd_cm
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
colnames(performance_data) <- c("High","Low","Middle")
performance_data
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
#colnames(performance_data) <- c("High","Low","Middle")
rownames(performance_data) <- c("Sensitivity/Recall Rate","Specificity","Precision", "Accuracy", "ROC-AUC")
performance_table <- as.table(performance_data)
xkabledply(performance_table)
performance_data <- matrix(c(manual_cm$byClass[1],bkwd_cm$byClass[1],fwd_cm$byClass[1],exh_bic_cm$byClass[1],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[2:2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[2:2]),manual_cm$byClass[2],bkwd_cm$byClass[2],fwd_cm$byClass[2],exh_bic_cm$byClass[2],cmdtt[1:1]/(cmdtt[1:1]+cmdtt[1,2]),rf_cm[1:1]/(rf_cm[1:1]+rf_cm[1,2]), manual_cm$byClass[5],bkwd_cm$byClass[5],fwd_cm$byClass[5],exh_bic_cm$byClass[5],cmdtt[4:4]/(cmdtt[4:4]+cmdtt[1,2]),rf_cm[4:4]/(rf_cm[4:4]+rf_cm[1,2]), manual_accuracy,bkwd_accuracy,fwd_accuracy,exh_bic_accuracy,accuracy_tune(tune_fit),1-missing_classerr, auc(h_manual), auc(bkwd_h), auc(fwd_h), auc(h_exh_bic), auc(dt_h), auc(rf_h)),ncol=6,byrow=TRUE)
colnames(performance_data) <- c("Manual","Backward","Forward","Exhaustive","Decision Tree","Random Forest")
rownames(performance_data) <- c("Sensitivity/Recall Rate","Specificity","Precision", "Accuracy", "ROC-AUC")
performance_table <- as.table(performance_data)
xkabledply(performance_table)
