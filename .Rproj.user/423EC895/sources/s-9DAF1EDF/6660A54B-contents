---
title: "Intro to DS - Linear Model part 2, and Feature Selection"
author: "Ricardo Diaz"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# HW assignment 

## Linear model - continued, bikeshare data

### Question 1  
**Import the data, call it `bikeorig.`**  
Like last time, import the data, remove unwanted columns, and check column data type. Again, select only the rush hour (`Hour`=16) data.  

```{r}

bikeorig = data.frame(read.csv("bikedata.csv"))
# head(bikeorig)
str(bikeorig)
```
```{r}
bike = subset(bikeorig, select = -c(Date, Casual.Users, Registered.Users))
str(bike)
colnames(bike)[4:11] = c("Day","Workday","Weather","TempF","TempFF","Humidity","Wind","Tusers")
str(bike)

bike16 <- subset(bike, Hour == 16 )
head(bike16)
```


### Question 2    
**Use ANOVA to compare the three different models you found in previous homework.**  
You have found three different models last time. Use ANOVA test to compare their residuals. What conclusions can you draw just from ANOVA?
```{r}
bike_final = bike16
bike_final$Season = factor(bike16$Season)
#bike_final$Hour = factor(bike16$Hour)
bike_final$Holiday = factor(bike16$Holiday)
bike_final$Day = factor(bike16$Day)
bike_final$Workday = factor(bike16$Workday)
bike_final$Weather = factor(bike16$Weather)
str(bike_final)
model1 = lm(Tusers ~ TempFF, data=bike_final)
model2 = lm(Tusers ~ TempFF + Humidity, data=bike_final)
model3 = lm(Tusers ~ TempFF +  Humidity + Wind, data=bike_final)

aovresult <- anova(model1, model2, model3)
xkabledply(aovresult)

```
Model 2 is better that Model 1 the amount of residual is less and the pvalue is 0,0. Model 3 is better that model 2 because it has less residual and a pvalue of 0.03 which is less that the signficance level. 

### Question 3  
**Build models with interaction terms.**  
Let us build models with interaction terms between a categorical and a numerical variable. Choose one numeric, and one categorical variable (with more than two levels) to build the model. First write down the model result as a single model with complex coefficients depending on the scenarios. Then re-write the results as separate models for the different subsets with various levels for the categorical variable.

```{r}
#lm(Tusers ~ TempF:Season, data = bike_final)
mod1 <- lm(Tusers ~ TempF*Weather, data = bike_final)
mod1
xkabledply(mod1)
# various <- bike_final
# str(various)
# various$Season = factor(various$Season, levels = c('1','2','3','4'))
# mod2 <- lm(Tusers ~ Season, data = various)
# summary(mod2)
# bike_trial <- bike_final


```

Weather 1: Tusers = 67.36 - 0 - (4- 0) * TempF

Weather 2: Tusers = 67.36 - 149.01 - (4-2.342) * TempF

Weather 3: Tusers = 67.36 - 187.97 - (4-0.973) * TempF

Weather 4: Tusers = 67.36 - 171.20 - (4- 0 )* TempF


### Question 4  
**Coefficient p-value and VIF checks.**  
Make sure you check these values, interpret them appropriately, and give comments. 
 
```{r}
xkabledply(mod1)
xkablevif(mod1)
```
TempF:Weather2, TempF:Weather3, Weather2	,Weather3 have vif > 10 which is not acceptable and we can conclude there is barely any correlation.
Weather 4 and TempF:Weather3 pvalue surpass the signifance value. This is not a good model.



### Question 5   
**Interaction term between two categorical variables**  
Try add an interaction term between two categorical variable this time to the one in question 4. At least one categorical variable should have more than 2 levels. What do you observe?  Explain the result to a laymen in your own way.   

```{r}
#str(bike_trial)
mod3 <- lm(Tusers ~ TempF*Weather + Season*Weather  , data = bike_final) ## * : for varibles cat
xkabledply(mod3)


```



### Question 6   
**One more check.**  
Look at the residuals, leverage, influence and cook's distance plot for this latest model. Comment on the result. 

```{r}
plot(mod3)
```

Our Normal quantile plot shows our data is normaly distributed.
The residuals vs. fitted plot appears to be relatively flat and homoskedastic.
In the scale location plot is roughly horizontal across the plot which means homoscedaticity and there is not pattern among the residuals
Residuals vs Levarage we can identify the points which have more influence are 0.01 cook distance.

## Feature Selection - Ozone Dataset in LA (1976)  
This section uses the ozone dataset in the “[faraway](https://www.rdocumentation.org/packages/faraway/versions/1.0.7/topics/ozone)” package. 
```{r}
loadPkg("faraway")
ozdf = faraway::ozone

```

### Question 7 
**Determine if the `O3` (ozone concentration) and `temp` variables are normal.**  

```{r}
#ozdf$O3 <- factor(ozdf$O3) categorical?
#str(ozdf)
#sum(is.na(ozdf$O3))
#sum(is.na(ozdf$temp))


```
Yes there are normal, both are numerical with no NA values.

### Question 8  
**Apply Pearson and Spearman measure on the two variables `O3` and `temp`.**  
Which one of these two is suitable for this scenario according to the summary pdf, and why?

```{r}

cor.test(ozdf$temp, ozdf$O3, method = 'pearson') 
cor.test(ozdf$temp, ozdf$O3, method = 'spearman')

# cor.test(mtc$disp,as.numeric(mtc$cyl), method="pearson")
# cor.test(mtc$disp,as.numeric(mtc$cyl), method="spearman")

```
Pearson is the most appropiate for meaurements taken from a interval variables, in this case because our two variables Pearson is the right approach

### Question 9  
**Make a model for visibility (`vis`) with other variables as predictors in the dataset.**  
Since we do not have a lot of variables, we can use the exhaustive method in regsubsets to identify what factors are best used to predict visibility. 
Also select `nbest = 2`. According to adjusted R2, what is the best model? What are the features to use? 
Build out that model and find the adjusted R2 value as well as the VIF. Are you pleased with this model?

```{r}
loadPkg("leaps")
loadPkg("faraway")
reg <- regsubsets(vis ~., data = ozdf, nvmax = 9, nbest = 2, method = 'exhaustive' )
plot(reg, scale = "adjr2", main = "Adjusted R^2")

# plot(reg, scale = "r2", main = "R^2")
# plot(reg, scale = "bic", main = "BIC")
# plot(reg, scale = "Cp", main = "Cp")

fit <- lm(vis ~ O3+vh+wind+humidity+temp+ibh+doy,data = ozdf)
summary(fit)
xkabledply(fit)
xkablevif(fit)
#str(ozdf)
```


We take 7 variables: O3, vh, wind, humidity, temp, ibh, doy for our model. The VIF of the features are good but the pvalues of wind and temp are higher that the signficance level. Our adjusted R value is 0.318 which indicates 32% of the variation of vis can be explain from the variation of our selected features. We are pleased with this model.



### Question 10  
**From the same result in the previous question, but use BIC instead.**  
Build the best model with this criterion and find the adjusted $R^2$ as well as VIF. Are you pleased with this model? 


```{r}
plot(reg, scale = "bic", main = "BIC")
fit2 <- lm(vis ~ wind+humidity+ibh+doy,data = ozdf)
summary(fit2)
xkabledply(fit2)
xkablevif(fit2)
```
According to BIC we take 3 variables: wind, humidity, ibh. The vif of our features are around 1 which is very good. The pvalues of humidity, idh and doy are excelent but the wind pvalues is above the signifance level. Yes im pleased with this model. Our adjusted R square value is 0.297 which mean the selected features explain 30% of the variation of vis.

### Question 11   
**To use $C_p$, we should use the stopping rule of $C_p$ ≈ (# regressors + 1).**  
Follow the example in class (or [this example](https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html)) to produce a visual graph for the task. Build out the best model again and find the adjusted $R^2$  value and VIF. 

```{r}
loadPkg("car")

reg1 <- regsubsets(vis ~., data = ozdf, nvmax = 9, nbest = 1, method = 'exhaustive' )

#reg <- regsubsets(vis ~., data = ozdf, nvmax = 9, nbest = 2, method = 'exhaustive' )


car::subsets(reg1, statistic="cp", legend = FALSE, min.size = 5, main = "Mallow Cp")
abline(a = 1, b = 1, lty = 2)


#plot(reg, scale = "Cp", main = "Cp")

fit3 <- lm(vis ~ O3+wind+humidity+ibh+doy,data = ozdf)
summary(fit3)
xkabledply(fit3)
xkablevif(fit3)

```
We take 6 variables: O3 , wind, humidity , ibh, doy . Our features vif values are aceptable and Our adjusted R square value is 0.314 which mean the selected features explain 31% of the variation of vis.

### Question 12   
**While you are at Question 11, also produce the graph for using adjusted R2 as criterion.**  
This won’t change the result in Question 9. This is just an alternative visualization for the adjusted $R^2$ case. We can see better how different are the nearby models.

```{r}

car::subsets(reg1, statistic="adjr2", legend = FALSE, min.size = 5, main = "Adjusted R^2")

```



### Question 13  
**Using ANOVA, compare the models you found in questions 9, 10, and 11.**  
Comment on the result.


```{r}

aovresult <- anova(fit,fit2,fit3)
xkabledply(aovresult)

```

Our first model have the lowest RSS, we can conclude this significantly better than the other models. Model 3 is a lot better that model 3 statistical wise, with improved RSS AND pvalue. 


