---
title: "Mini Project Team 2"  
authors: "By: Cooper Atkins, Ricardo Diaz, Varun Shah, and Nusrat Nawshin"  
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
library(dplyr)
library(lmtest)
library(vcd)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# use scipen=999 to prevent scientific notation at all times
```
```{r loanpredict, results='markup'}
#Import dataset
loanpredict <- read.csv("Training Data.csv", header = TRUE)
#Convert necessary variables to factors/categoricals and set appropriate level titles
loanpredict$Married.Single <- recode_factor(loanpredict$Married.Single, single = "Single", married = "Married")
loanpredict$House_Ownership <- recode_factor(loanpredict$House_Ownership, rented = "Renting", owned = "Owning", norent_noown = "Neither")
loanpredict$Car_Ownership <- recode_factor(loanpredict$Car_Ownership, no = "No", yes = "Yes")

loanpredict$Risk_Flag <- factor(loanpredict$Risk_Flag)
#Remove variables that won't help in our analysis
loandata <- subset(loanpredict, select = -c(Id, CITY, STATE, Profession))
str(loandata)
summary(loandata)
```

```{r}
dplyr::count(loandata, Risk_Flag, sort = TRUE)
```

```{r}
barplot(prop.table(table(loandata$Risk_Flag)),
        col = rainbow(2),
        # ylim = c(0, 0.7),
        main = "Class Distribution")
```
Data Partition
Lets partition the dataset into train dataset and test dataset based on set.seed.

```{r}

set.seed(123)
ind <- sample(2, nrow(loandata), replace = TRUE, prob = c(0.75, 0.25))
train <- loandata[ind==1,]
test <- loandata[ind==2,]
```

Predictive Model Data
Let create a model based on the training dataset and look at the classification in the training dataset.

```{r}
table(train$Risk_Flag)
```

We can see that 188 observations in class 154691 and 21516  observations in class 1.

Discriminant analysis in R
```{r}
prop.table(table(train$Risk_Flag))
```


Based on proportion table 87% in one class and 12% in another class.

Over Sampling

```{r}
library(ROSE)
over <- ovun.sample(Risk_Flag~., data = train, method = "over", N = 331698)$data
table(over$Risk_Flag)
```


This is based on resampling and now both the classes are equal.

```{r}
summary(over)
```



Full Model:
```{r, results='markup'}

#defLogit <- glm(Risk_Flag ~ Income +Age +Experience+Married.Single+House_Ownership+Car_Ownership+CURRENT_JOB_YRS+CURRENT_HOUSE_YRS , data = loandata, family = "binomial")

# defLogit <- glm(Risk_Flag ~ ., data = over, family = "binomial")
defLogit <- glm(Risk_Flag ~ ., data = loandata, family = "binomial")

summary(defLogit)

# xkabledply(defLogit, title = paste("Logistic Regression :", format(formula(defLogit)) ))
```


Forward selection:
```{r}
library(MASS)
 
fwd <- stepAIC(defLogit, direction = "forward", trace = FALSE)

summary(fwd)

xkabledply(fwd, title = paste("Logistic Regression :", format(formula(fwd)) ))
```

```{r}
# Specify a null model with no predictors
null_model <- glm(Risk_Flag ~ 1, data = loandata, family = "binomial")

# Specify the full model using all of the potential predictors
full_model <- glm(Risk_Flag ~ ., data = loandata, family = "binomial")

# Use a forward stepwise algorithm to build a parsimonious model(
bkwrd_step_model <- step(full_model, scope = list(lower = null_model, upper = full_model), direction = "backward", k=log(nrow(loandata)))
```

--------------------------------------------------------------------------------------------------

Backward selection on AIC:


```{r}
# Specify a null model with no predictors
null_model <- glm(Risk_Flag ~ 1, data = loandata, family = "binomial")

# Specify the full model using all of the potential predictors
full_model <- glm(Risk_Flag ~ ., data = loandata, family = "binomial")

# Use a backward stepwise algorithm on AIC to build a parsimonious model
bkwrd_AIC_model_vars <- step(full_model, scope = list(lower = null_model, upper = full_model), direction = "backward", k=2)
```

If we consider AIC as a criterion we should have all the 8 variables in the logistics model.

Now let's the the VIF score to find out the multicolinearity.
```{r}
# library(car)
# xkablevif(full_model, wide=FALSE)
vif(full_model)
```


Backward selection on BIC:

```{r}
# Use a backward stepwise algorithm on BIC to build a parsimonious model
bkwrd_BIC_model_vars <- step(full_model, scope = list(lower = null_model, upper = full_model), direction = "backward", k=log(nrow(loandata)))
```

From backward selection with BIC as criteria we are getting 6 features. It excluded Income and CURRENT_HOUSE_YRS. Now let's make a model with these 6 features.


```{r}

bkwd_bic_model <- glm(Risk_Flag ~ CURRENT_JOB_YRS+Age+Married.Single+Car_Ownership+House_Ownership+Experience, data = loandata, family = "binomial")
summary(bkwd_bic_model)

```

Now let's the the VIF score to find out the multicolinearity.
```{r}
# library(car)
# xkablevif(bkwd_bic_model, wide=FALSE)
vif(bkwd_bic_model)
```

All the VIF scores are satisfactory. It means we don't have multicolinearity in this model.

---------------------------------------------------------------------------------------------------
```{r}
#library(MASS)
#AIC
bkwd_aic <- stepAIC(defLogit, direction = "backward", trace = FALSE)

summary(bkwd_aic)

xkabledply(bkwd_aic, title = paste("Logistic Regression :", format(formula(bkwd_aic)) ))
```

Backward selection on BIC:
```{r}
#library(MASS)
#BIC
bkwd_bic<- stepAIC(defLogit, direction = "backward", trace = FALSE, k=log(nrow(loandata)))

summary(bkwd_bic)

xkabledply(bkwd_bic, title = paste("Logistic Regression :", format(formula(bkwd_bic)) ))
```


```{r}
library(caret)
varImp(bkwd_bic)
```


```{r growthDecayFactors, results='markup', collapse=F}
expcoeff = exp(coef(bkwd_bic))
# expcoeff
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" )
```

From these results, we can say, for example:

* The log(odds-ratio) for being defaulted decrease by a factor of `r format(expcoeff[2],digit=6)` for each year of age increase. 
* The increment of Experience of 1 year will also decrease the log(odds-ratio) much better by a factor of `r format(expcoeff[3],digit=4)`. 
* The effect of being from married, compared to unmarried, is hurting by a factor of `r format(expcoeff[4],digit=4)`, for the log(odds-ratio).
* The effect of being from a house ownership, compared to house renter, is hurting little less, by a factor of `r format(expcoeff[5],digit=4)`, again, for the log(odds-ratio). 
* The effect of being from a car owner, compared to not having a car, is hurting little more, by a factor of `r format(expcoeff[5],digit=4)`, again, for the log(odds-ratio).  
* The log(odds-ratio) for being defaulted increase by a factor of `r format(expcoeff[6],digit=4)` for each year of current job experience increase.  




<!-- Confidence Intervals -->

<!-- We can easily determine the confidence intervals of each coefficient with these two slightly different ways:   -->
```{r ConfInt, results='markup', collapse=F}
# ## CIs using profiled log-likelihood
# # confint(admitLogit)
# xkabledply( confint(bkwd_bic), title = "CIs using profiled log-likelihood" )
# ## CIs using standard errors
# # confint.default(admitLogit)
# xkabledply( confint.default(bkwd_bic), title = "CIs using standard errors" )
```


Model evaluation
Confusion matrix 

This is just one of the many libraries you can find the confusion matrix. It is easy to use, but not very powerful, lacking ability to choose cutoff value, and it does not give you all the metrics like accuracy, precision, recall, sensitivity, f1 score etc. Nonetheless, it's handy.


```{r confusionMatrix, results='markup'}
loadPkg("regclass")
cm <- confusion_matrix(bkwd_bic)
#cm1
xkabledply( cm, title = "Confusion matrix from Logit Model" )
unloadPkg("regclass")
accuracy = (cm[1] +cm[5]) / cm[9]
#accuracy

```

Accuracy of the model is `r round(accuracy * 100) ` %


  

The Hosmer and Lemeshow Goodness of Fit test can be used to evaluate logistic regression fit. 

```{r HosmerLemeshow}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
bkwdLogitHoslem = hoslem.test(loandata$Risk_Flag, fitted(bkwd_bic)) # Hosmer and Lemeshow test, a chi-squared test
bkwdLogitHoslem
unloadPkg("ResourceSelection") 
```

<!-- The p-value of `r bkwdLogitHoslem$p.value` is very low. This indicates the model is not really a good fit. -->



<!-- The p-value of `r bkwdLogitHoslem$p.value` is relatively high. This indicates the model is not really a good fit, despite all the coefficients are significant.  -->

#### Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC) measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The area-under-curve is always between 0.5 and 1. Values higher than 0.8 is considered good model fit.  
```{r roc_auc}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(bkwd_bic, type = "response" )
over$prob=prob
h <- roc(Risk_Flag~prob, data=over)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
# unloadPkg("pROC")
```


<!-- We have here the area-under-curve of `r auc(h)`, which is less than 0.8. This test also agrees with the Hosmer and Lemeshow test that the model is not considered a good fit.  -->


EDA

```{r}

def.ms=table(loanpredict$Married.Single, loanpredict$Risk_Flag)
#def.ms$total = 
def.ms <- cbind(def.ms, total = rowSums(def.ms)) # make new column total with row sum
# def.ms <- cbind(def.ms, Status = row.names(def.ms)) #make new column with Marital Status

df <-  data.frame(def.ms)


colnames(df)[which(names(df) == 'X0')] <- "Not.Defaulted"
colnames(df)[which(names(df) == 'X1' )] <- "Defaulted"
```

```{r}

df <- df%>%group_by(Not.Defaulted)%>%mutate(Not.DefaultedPercentage=round(as.numeric(Not.Defaulted)/as.numeric(total)*100,2))
df <- df%>%group_by(Defaulted)%>%mutate(DefaultedPercentage=round(as.numeric(Defaulted)/as.numeric(total)*100,2))

# df
```


```{r}
df2 <- subset(df, select = c(Not.DefaultedPercentage, DefaultedPercentage))
xx <- barplot(t(as.matrix(df2)),beside=TRUE, names.arg = c("Single", "Married"), main="Percentage of default by marital status", ylab="percentage of default(%)", col = c('blue','red'), legend.text = c("Not.DefaultedPercentage","DefaultedPercentage"))
```






